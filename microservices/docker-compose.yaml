services:
  backend_1:
    build: 
      context: backend
      dockerfile: Dockerfile
    env_file:
      - ./backend/.env
    depends_on:
      haproxy_db:
        condition: service_healthy
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 10s
    networks:
      - lb-net

  backend_2:
    build: 
      context: backend
      dockerfile: Dockerfile
    env_file:
      - ./backend/.env
    depends_on:
      haproxy_db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 10s
    networks:
      - lb-net
    
  frontend_1:
    build:
      context: frontend
      dockerfile: Dockerfile
    env_file:
      - ./frontend/.env
    depends_on:
      backend_1:
        condition: service_healthy
      backend_2:
        condition: service_healthy

    networks:
      - lb-net
    
  frontend_2:
    build:
      context: frontend
      dockerfile: Dockerfile
    env_file:
      - ./frontend/.env
    depends_on:
      backend_1:
        condition: service_healthy
      backend_2:
        condition: service_healthy

    networks:
      - lb-net

  haproxy_1:
    image: haproxy:2.9
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      backend_1:
        condition: service_healthy
      backend_2:
        condition: service_healthy

    networks:
      - lb-net

  haproxy_2:
    image: haproxy:2.9
    restart: always
    ports:
      - "8080:80"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      backend_1:
        condition: service_healthy
      backend_2:
        condition: service_healthy
    networks:
      - lb-net

  etcd:
    image: quay.io/coreos/etcd:v3.5.16
    restart: always
    environment:
      - ETCDCTL_API=3
    command: >
      etcd
      --name etcd0
      --data-dir /etcd-data
      --advertise-client-urls http://etcd:2379
      --listen-client-urls http://0.0.0.0:2379
      --listen-peer-urls http://0.0.0.0:2380
      --initial-advertise-peer-urls http://etcd:2380
      --initial-cluster etcd0=http://etcd:2380
      --initial-cluster-state new
      --initial-cluster-token patroni-etcd-cluster
      --enable-v2=true
    volumes:
      - ./data/etcd_data:/etcd-data
    healthcheck:
      test: ["CMD", "etcdctl", "--endpoints=http://127.0.0.1:2379", "endpoint", "health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    networks:
      - lb-net

  patroni_1:
    image: ghcr.io/zalando/spilo-16:3.3-p1
    restart: always
    environment:
      - SCOPE=pg-cluster
      - ETCD_HOST=etcd:2379
      - PGUSER_SUPERUSER=postgres
      - PGPASSWORD_SUPERUSER=postgres_password
      - PGUSER_STANDBY=standby
      - PGPASSWORD_STANDBY=standby_password
      - PGUSER_ADMIN=admin
      - PGPASSWORD_ADMIN=admin_password
      - PGDATA=/home/postgres/pgdata/pgroot/data
      - ALLOW_NOSSL=true
    depends_on:
      etcd:
        condition: service_healthy
    volumes:
      - ./data/patroni_1_data:/home/postgres/pgdata
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8008/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - lb-net

  patroni_2:
    image: ghcr.io/zalando/spilo-16:3.3-p1
    restart: always
    environment:
      - SCOPE=pg-cluster
      - ETCD_HOST=etcd:2379
      - PGUSER_SUPERUSER=postgres
      - PGPASSWORD_SUPERUSER=postgres_password
      - PGUSER_STANDBY=standby
      - PGPASSWORD_STANDBY=standby_password
      - PGUSER_ADMIN=admin
      - PGPASSWORD_ADMIN=admin_password
      - PGDATA=/home/postgres/pgdata/pgroot/data
      - ALLOW_NOSSL=true
    depends_on:
      etcd:
        condition: service_healthy
    volumes:
      - ./data/patroni_2_data:/home/postgres/pgdata
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8008/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - lb-net

  pgpool_1:
    build:
      context: pgpool
      dockerfile: Dockerfile
    restart: always
    depends_on:
      patroni_1:
        condition: service_healthy
      patroni_2:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres -h localhost -p 5432"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - lb-net

  pgpool_2:
    build:
      context: pgpool
      dockerfile: Dockerfile
    restart: always
    depends_on:
      patroni_1:
        condition: service_healthy
      patroni_2:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres -h localhost -p 5432"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - lb-net

  haproxy_db:
    image: haproxy:2.9
    restart: always
    volumes:
      - ./haproxy/haproxy-db.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      pgpool_1:
        condition: service_healthy
      pgpool_2:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "haproxy -c -f /usr/local/etc/haproxy/haproxy.cfg"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - lb-net

networks:
  lb-net:
    driver: bridge

volumes:
  ./data/etcd_data:
  ./data/patroni_1_data:
  ./data/patroni_2_data: